import aiohttp
import base64
from io import BytesIO
from PIL import Image
from colorama import Fore, Style

# é…ç½®APIå¯†é’¥ (ç¡¬ç¼–ç è­¦å‘Š)
API_KEYS = {
    "SILICONFLOW": "",
    "GLM": "",
    "QWQ": ""
}

# å¯çˆ±çš„æ—¥å¿—å‡½æ•°
def log_info(msg): print(f"{Fore.GREEN}ğŸŒ¸ {msg}{Style.RESET_ALL}")
def log_warning(msg): print(f"{Fore.YELLOW}âš ï¸ {msg}{Style.RESET_ALL}")
def log_error(msg): print(f"{Fore.RED}ğŸ’¥ {msg}{Style.RESET_ALL}")

async def format_with_deepseek(original_content, raw_answers):
    """æ•´ç†ç­”æ¡ˆæ ¼å¼"""
    try:
        async with aiohttp.ClientSession() as session:
            payload = {
                "model": "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B",
                "messages": [{
                    "role": "user",
                    "content": f"è¯·å¸®æˆ‘æ•´ç†ä»¥ä¸‹å†…å®¹æ ¼å¼ï¼š\n{original_content}\nç”Ÿæˆçš„ç­”æ¡ˆï¼š\n{raw_answers}"
                }],
                "temperature": 0.7,
                "top_p": 0.7
            }
            async with session.post(
                url="https://api.siliconflow.cn/v1/chat/completions",
                headers={"Authorization": f"Bearer {API_KEYS['SILICONFLOW']}"},
                json=payload
            ) as resp:
                if resp.status != 200:
                    log_error(f"DeepSeek API é”™è¯¯: HTTP {resp.status}")
                    return None
                data = await resp.json()
                return data.get("choices", [{}])[0].get("message", {}).get("content", "").strip()
    except Exception as e:
        log_error(f"DeepSeekè°ƒç”¨å¼‚å¸¸: {str(e)}")
        return None

async def image_to_markdown(image_path):
    """å›¾ç‰‡è½¬Markdown"""
    try:
        # å›¾ç‰‡è½¬base64
        with Image.open(image_path) as img:
            buffer = BytesIO()
            img.save(buffer, format="PNG")
            img_base64 = base64.b64encode(buffer.getvalue()).decode("utf-8")

        async with aiohttp.ClientSession() as session:
            payload = {
                "model": "glm-4v-flash",
                "messages": [{
                    "role": "user",
                    "content": [
                        {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{img_base64}"}},
                        {"type": "text", "text": "è¯·å°†å›¾ç‰‡å†…å®¹è½¬å†™ä¸ºMarkdownæ ¼å¼"}
                    ]
                }]
            }
            async with session.post(
                url="https://open.bigmodel.cn/api/paas/v4/chat/completions",
                headers={"Authorization": f"Bearer {API_KEYS['GLM']}"},
                json=payload
            ) as resp:
                if resp.status != 200:
                    log_error(f"GLM API é”™è¯¯: HTTP {resp.status}")
                    return None
                data = await resp.json()
                return data.get("choices", [{}])[0].get("message", {}).get("content", "").strip()
    except Exception as e:
        log_error(f"å›¾ç‰‡å¤„ç†å¼‚å¸¸: {str(e)}")
        return None

async def generate_answers(prompt, temperature=0.36, max_tokens=1024):
    """ç”Ÿæˆç­”æ¡ˆ (å¸¦æ¸©åº¦æ§åˆ¶)"""
    try:
        async with aiohttp.ClientSession() as session:
            payload  = {
        "model": "free:QwQ-32B",
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.36,
        "max_tokens": 1024  # å¦‚æœè¿™é‡Œè¿‡å¤§ï¼Œä¼šå¯¼è‡´ API è°ƒç”¨å¤±è´¥ ç–‘ä¼¼æ˜¯APIç½‘å…³æˆ–åç«¯æœåŠ¡é€šå¸¸å¯¹å•æ¬¡è¯·æ±‚çš„æœ€å¤§å¤„ç†æ—¶é—´ æœ‰é™åˆ¶ï¼ˆå¦‚30ç§’ï¼‰
    }
            async with session.post(
                url="https://api.suanli.cn/v1/chat/completions",
                headers={"Authorization": f"Bearer {API_KEYS['QWQ']}"},
                json=payload
            ) as resp:
                if resp.status != 200:
                    log_error(f"QWQ API é”™è¯¯: HTTP {resp.status}")
                    return None
                data = await resp.json()
                return data.get("choices", [{}])[0].get("message", {}).get("content", "").strip()
    except Exception as e:
        log_error(f"ç­”æ¡ˆç”Ÿæˆå¼‚å¸¸: {str(e)}")
        return None